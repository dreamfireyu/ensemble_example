{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greedy Ensemble example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we use cifar10 to show you the performance of greedy ensemble operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                                            torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "tr_set = torchvision.datasets.CIFAR10(root = \"./datasets/cifar10\", train = True, download = True, transform = transform)\n",
    "te_set = torchvision.datasets.CIFAR10(root = \"./datasets/cifar10\", train = False, download = True, transform = transform)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "tr_data = torch.utils.data.DataLoader(tr_set, batch_size = batch_size, shuffle = True)\n",
    "te_data = torch.utils.data.DataLoader(te_set, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use get_feature() to extract images and labels from original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_feature(data_set):\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(DataLoader(data_set,batch_size=64)):\n",
    "\n",
    "            all_features.append(images)\n",
    "            all_labels.append(labels)\n",
    "\n",
    "    return torch.cat(all_features).cpu().numpy(), torch.cat(all_labels).cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we select two different models for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import towhee\n",
    "from towhee import ops\n",
    "op = ops.image_embedding.timm(model_name ='resnet50', num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "op2 = ops.image_embedding.timm(model_name ='resnet101', num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from towhee.trainer.training_config import TrainingConfig\n",
    "\n",
    "training_config = TrainingConfig(\n",
    "    batch_size=64,\n",
    "    epoch_num=15,\n",
    "    output_dir='cifar10_output1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_config2 = TrainingConfig(\n",
    "    batch_size=64,\n",
    "    epoch_num=15,\n",
    "    output_dir='cifar10_output2'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-13 10:43:20,921 - 139635262112320 - trainer.py-trainer:319 - WARNING: TrainingConfig(output_dir='cifar10_output1', overwrite_output_dir=True, eval_strategy='epoch', eval_steps=None, batch_size=64, val_batch_size=-1, seed=42, epoch_num=15, dataloader_pin_memory=True, dataloader_drop_last=True, dataloader_num_workers=0, lr=5e-05, metric='Accuracy', print_steps=None, load_best_model_at_end=False, early_stopping={'monitor': 'eval_epoch_metric', 'patience': 4, 'mode': 'max'}, model_checkpoint={'every_n_epoch': 1}, tensorboard={'log_dir': None, 'comment': ''}, loss='CrossEntropyLoss', optimizer='Adam', lr_scheduler_type='linear', warmup_ratio=0.0, warmup_steps=0, device_str=None, sync_bn=False, freeze_bn=False)\n",
      "[epoch 1/15] loss=2.106, metric=0.286, eval_loss=2.057, eval_metric=0.426: 100%|██████████| 781/781 [00:52<00:00, 14.79step/s]\n",
      "[epoch 2/15] loss=1.537, metric=0.511, eval_loss=1.504, eval_metric=0.558: 100%|██████████| 781/781 [00:55<00:00, 14.03step/s]\n",
      "[epoch 3/15] loss=1.179, metric=0.617, eval_loss=1.17, eval_metric=0.635: 100%|██████████| 781/781 [00:53<00:00, 14.60step/s] \n",
      "[epoch 4/15] loss=0.993, metric=0.685, eval_loss=0.994, eval_metric=0.675: 100%|██████████| 781/781 [00:53<00:00, 14.72step/s]\n",
      "[epoch 5/15] loss=0.88, metric=0.729, eval_loss=0.886, eval_metric=0.704: 100%|██████████| 781/781 [00:53<00:00, 14.57step/s]\n",
      "[epoch 6/15] loss=0.79, metric=0.765, eval_loss=0.802, eval_metric=0.723: 100%|██████████| 781/781 [00:55<00:00, 14.12step/s]\n",
      "[epoch 7/15] loss=0.719, metric=0.791, eval_loss=0.735, eval_metric=0.742: 100%|██████████| 781/781 [00:53<00:00, 14.55step/s]\n",
      "[epoch 8/15] loss=0.643, metric=0.818, eval_loss=0.667, eval_metric=0.753: 100%|██████████| 781/781 [00:53<00:00, 14.73step/s]\n",
      "[epoch 9/15] loss=0.595, metric=0.84, eval_loss=0.623, eval_metric=0.763: 100%|██████████| 781/781 [00:53<00:00, 14.73step/s]\n",
      "[epoch 10/15] loss=0.545, metric=0.861, eval_loss=0.578, eval_metric=0.768: 100%|██████████| 781/781 [00:53<00:00, 14.68step/s]\n",
      "[epoch 11/15] loss=0.507, metric=0.876, eval_loss=0.543, eval_metric=0.778: 100%|██████████| 781/781 [00:57<00:00, 13.67step/s]\n",
      "[epoch 12/15] loss=0.465, metric=0.893, eval_loss=0.506, eval_metric=0.786: 100%|██████████| 781/781 [00:54<00:00, 14.44step/s]\n",
      "[epoch 13/15] loss=0.426, metric=0.909, eval_loss=0.473, eval_metric=0.788: 100%|██████████| 781/781 [00:54<00:00, 14.46step/s]\n",
      "[epoch 14/15] loss=0.396, metric=0.92, eval_loss=0.447, eval_metric=0.793: 100%|██████████| 781/781 [00:54<00:00, 14.32step/s]\n",
      "[epoch 15/15] loss=0.363, metric=0.932, eval_loss=0.42, eval_metric=0.795: 100%|██████████| 781/781 [01:03<00:00, 15.02step/s] "
     ]
    }
   ],
   "source": [
    "op.train(training_config, train_dataset=tr_set,eval_dataset=te_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-13 14:19:55,680 - 139635262112320 - trainer.py-trainer:319 - WARNING: TrainingConfig(output_dir='cifar10_output2', overwrite_output_dir=True, eval_strategy='epoch', eval_steps=None, batch_size=64, val_batch_size=-1, seed=42, epoch_num=15, dataloader_pin_memory=True, dataloader_drop_last=True, dataloader_num_workers=0, lr=5e-05, metric='Accuracy', print_steps=None, load_best_model_at_end=False, early_stopping={'monitor': 'eval_epoch_metric', 'patience': 4, 'mode': 'max'}, model_checkpoint={'every_n_epoch': 1}, tensorboard={'log_dir': None, 'comment': ''}, loss='CrossEntropyLoss', optimizer='Adam', lr_scheduler_type='linear', warmup_ratio=0.0, warmup_steps=0, device_str=None, sync_bn=False, freeze_bn=False)\n",
      "[epoch 1/15] loss=2.266, metric=0.167, eval_loss=2.254, eval_metric=0.209: 100%|██████████| 781/781 [01:24<00:00,  9.19step/s]\n",
      "[epoch 2/15] loss=2.078, metric=0.269, eval_loss=2.059, eval_metric=0.308: 100%|██████████| 781/781 [01:23<00:00,  9.37step/s]\n",
      "[epoch 3/15] loss=1.864, metric=0.348, eval_loss=1.852, eval_metric=0.367: 100%|██████████| 781/781 [01:23<00:00,  9.40step/s]\n",
      "[epoch 4/15] loss=1.705, metric=0.406, eval_loss=1.698, eval_metric=0.416: 100%|██████████| 781/781 [01:22<00:00,  9.42step/s]\n",
      "[epoch 5/15] loss=1.582, metric=0.459, eval_loss=1.577, eval_metric=0.464: 100%|██████████| 781/781 [01:23<00:00,  9.32step/s]\n",
      "[epoch 6/15] loss=1.469, metric=0.504, eval_loss=1.468, eval_metric=0.505: 100%|██████████| 781/781 [01:25<00:00,  9.18step/s]\n",
      "[epoch 7/15] loss=1.383, metric=0.534, eval_loss=1.383, eval_metric=0.527: 100%|██████████| 781/781 [01:24<00:00,  9.22step/s]\n",
      "[epoch 8/15] loss=1.3, metric=0.564, eval_loss=1.303, eval_metric=0.557: 100%|██████████| 781/781 [01:23<00:00,  9.40step/s]\n",
      "[epoch 9/15] loss=1.235, metric=0.591, eval_loss=1.238, eval_metric=0.579: 100%|██████████| 781/781 [01:23<00:00,  9.38step/s]\n",
      "[epoch 10/15] loss=1.166, metric=0.618, eval_loss=1.173, eval_metric=0.601: 100%|██████████| 781/781 [01:23<00:00,  9.38step/s]\n",
      "[epoch 11/15] loss=1.107, metric=0.641, eval_loss=1.114, eval_metric=0.614: 100%|██████████| 781/781 [01:22<00:00,  9.42step/s]\n",
      "[epoch 12/15] loss=1.048, metric=0.661, eval_loss=1.06, eval_metric=0.628: 100%|██████████| 781/781 [01:23<00:00,  9.38step/s]\n",
      "[epoch 13/15] loss=1.002, metric=0.685, eval_loss=1.014, eval_metric=0.646: 100%|██████████| 781/781 [01:23<00:00,  9.41step/s]\n",
      "[epoch 14/15] loss=0.948, metric=0.705, eval_loss=0.963, eval_metric=0.655: 100%|██████████| 781/781 [01:22<00:00,  9.41step/s]\n"
     ]
    }
   ],
   "source": [
    "op2.train(training_config2, train_dataset=tr_set,eval_dataset=te_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 98.56it/s]\n"
     ]
    }
   ],
   "source": [
    "images,labels = get_feature(te_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "imagestensor = torch.from_numpy(images).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict propability needs to be saved for greedy ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out = op.trainer.predict(te_set)\n",
    "out1 = op._op.trainer.predict(imagestensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "out2 = op2._op.trainer.predict(imagestensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(pre,labels):\n",
    "    ans=0\n",
    "    for i in range(len(pre)):\n",
    "        predict_num = torch.argmax(torch.softmax(pre[i], dim=-1)).item()\n",
    "        if(predict_num==labels[i]):\n",
    "            ans = ans+1\n",
    "    return ans/len(pre)*100.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the scores from the two models above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.31"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(out1,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.93"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(out2,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greedy Ensemble inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we use greedy ensemble operator to generate a new predict from previous models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "preds.append(out1.cpu().detach().numpy())\n",
    "preds.append(out2.cpu().detach().numpy())\n",
    "preds = np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from towhee import Entity,DataCollection\n",
    "dc = towhee.DataCollection([Entity(ens=preds,groud_truth = labels)]).unstream()\n",
    "dc = dc.greedy_ensemble[('ens','groud_truth'),'greedy_ens'](size=4,topk=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.72"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_pred = torch.from_numpy(dc[0].greedy_ens)\n",
    "label = torch.from_numpy(dc[0].groud_truth)\n",
    "score = evaluate(new_pred,label)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see approvement on score after greedy ensemble by 0.41."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ee8f9d005f921b11e37646322d569d83ab1bb8b2f1f9e1244f064a47f10136b5"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('ensemble')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
